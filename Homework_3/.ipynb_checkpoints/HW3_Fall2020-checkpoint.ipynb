{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Support Vector Machine and Decision Trees\n",
    "\n",
    "# Due on 11/30 23:59 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use the same affair dataset from HW2, but will skip the EDA phrase we have done enough of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everything removing outliers, create dummies variabes had been done for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_marriage</th>\n",
       "      <th>age</th>\n",
       "      <th>yrs_married</th>\n",
       "      <th>children</th>\n",
       "      <th>religious</th>\n",
       "      <th>educ</th>\n",
       "      <th>had_affair</th>\n",
       "      <th>occ2</th>\n",
       "      <th>occ3</th>\n",
       "      <th>occ4</th>\n",
       "      <th>occ5</th>\n",
       "      <th>occ6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate_marriage   age  yrs_married  children  religious  educ  had_affair  \\\n",
       "0            3.0  32.0          9.0       3.0        3.0  17.0           1   \n",
       "1            3.0  27.0         13.0       3.0        1.0  14.0           1   \n",
       "2            4.0  22.0          2.5       0.0        1.0  16.0           1   \n",
       "3            4.0  37.0         16.5       4.0        3.0  16.0           1   \n",
       "4            5.0  27.0          9.0       1.0        1.0  14.0           1   \n",
       "\n",
       "   occ2  occ3  occ4  occ5  occ6  \n",
       "0     1     0     0     0     0  \n",
       "1     0     1     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     1     0  \n",
       "4     0     1     0     0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember the affair data set from HW3, we will use that dataset again\n",
    "# but we will directly load from file\n",
    "orig_df = pd.read_csv(\"affairs2.csv\")\n",
    "# Set up our target class label\n",
    "orig_df['had_affair'] = orig_df['affairs'].apply(lambda x: 1 if x != 0 else 0)\n",
    "orig_df = orig_df.drop('affairs',axis=1)\n",
    "# remove NA\n",
    "orig_df.dropna(inplace=True)\n",
    "# create dummies variable for occupation\n",
    "occ = pd.get_dummies(orig_df['occupation'],drop_first=True)\n",
    "# we include rate_marriage feature as well. In HW3, we did not include that variable\n",
    "features = ['rate_marriage','age','yrs_married','children','religious','educ', 'had_affair']\n",
    "df = orig_df\n",
    "df = pd.concat([orig_df[features], occ], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rate_marriage    0\n",
       "age              0\n",
       "yrs_married      0\n",
       "children         0\n",
       "religious        0\n",
       "educ             0\n",
       "had_affair       0\n",
       "occ2             0\n",
       "occ3             0\n",
       "occ4             0\n",
       "occ5             0\n",
       "occ6             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure there is no missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are ready to build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Build a classification model using SVC using linear kernel with usual steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5092, 11)\n",
      "(5092,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the model from sklearn import svm, create the SVC object \n",
    "#model = svm.SVC()\n",
    "#Call Train test split\n",
    "#print out model performance\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "model = svm.SVC(kernel = 'linear')\n",
    "\n",
    "\n",
    "# X = df[features].as_matrix()\n",
    "# Y = df['had_affair'].as_matrix()\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('had_affair',axis=1), \n",
    "                                                    df['had_affair'], test_size=0.20, \n",
    "                                                    random_state=101)\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df[features], \n",
    "#                                                     df['had_affair'], test_size=0.20, \n",
    "#                                                     random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print (y_train.shape)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       850\n",
      "           1       0.64      0.27      0.38       424\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1274\n",
      "   macro avg       0.68      0.60      0.59      1274\n",
      "weighted avg       0.69      0.71      0.67      1274\n",
      "\n",
      "0.707221350078493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Now try different value of C-parameter and rerun your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81       850\n",
      "           1       0.64      0.25      0.36       424\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1274\n",
      "   macro avg       0.68      0.59      0.59      1274\n",
      "weighted avg       0.69      0.70      0.66      1274\n",
      "\n",
      "0.7048665620094191\n"
     ]
    }
   ],
   "source": [
    "# Try C = 2**-5 and 2**5\n",
    "\n",
    "model = svm.SVC(kernel = 'linear', C = 2**-5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81       850\n",
      "           1       0.64      0.27      0.38       424\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1274\n",
      "   macro avg       0.68      0.60      0.59      1274\n",
      "weighted avg       0.69      0.71      0.66      1274\n",
      "\n",
      "0.7056514913657771\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel = 'linear', C = 2**5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3. Try using rbf as your kernel and use Gamma of 2**-5, 0.1, 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       850\n",
      "           1       0.64      0.31      0.42       424\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      1274\n",
      "   macro avg       0.68      0.61      0.61      1274\n",
      "weighted avg       0.70      0.71      0.68      1274\n",
      "\n",
      "0.7111459968602826\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel = 'rbf', gamma = 2**-5)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       850\n",
      "           1       0.59      0.31      0.41       424\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1274\n",
      "   macro avg       0.66      0.60      0.60      1274\n",
      "weighted avg       0.68      0.70      0.67      1274\n",
      "\n",
      "0.7001569858712716\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel = 'rbf', gamma = 0.1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.77       850\n",
      "           1       0.47      0.24      0.32       424\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      1274\n",
      "   macro avg       0.58      0.55      0.55      1274\n",
      "weighted avg       0.62      0.66      0.62      1274\n",
      "\n",
      "0.6577708006279435\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel = 'rbf', gamma = 1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       850\n",
      "           1       0.40      0.16      0.23       424\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1274\n",
      "   macro avg       0.54      0.52      0.50      1274\n",
      "weighted avg       0.59      0.64      0.59      1274\n",
      "\n",
      "0.6420722135007849\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel = 'rbf', gamma = 2)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. So out of all the models you try in Question 2 and 3, what is the best choice for the kernel, C and gamma parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best C value is: 2^5 (2\\*\\*5) = 32. <br> \n",
    "The best Gamma value is: 2^(-5) (2\\*\\*-5) = .03125 <br>\n",
    "The best kernel is rbf with a 71% performance accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will try to fit the same dataset with Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5. Build a Decision Tree Classifier using default parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Now try using max_depth = 2, 3, 4 and crierion = 'gini' and 'entropy' to build 3 X 2 = 6 different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7. What is your obsevation from Question 6? Does the choice of the criterion important in this case? What about the max_depth? What is the best choice of max_depth and criterion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Visualization\n",
    "\n",
    "Scikit learn actually has some built-in visualization capabilities for decision trees, you won't use this often and it requires you to install the pydot library, but here is an example of what it looks like and the code to execute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rate_marriage', 'age', 'yrs_married', 'children', 'religious', 'educ',\n",
       "       'had_affair', 'occ2', 'occ3', 'occ4', 'occ5', 'occ6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rate_marriage',\n",
       " 'age',\n",
       " 'yrs_married',\n",
       " 'children',\n",
       " 'religious',\n",
       " 'educ',\n",
       " 'had_affair']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rate_marriage',\n",
       " 'age',\n",
       " 'yrs_married',\n",
       " 'children',\n",
       " 'religious',\n",
       " 'educ',\n",
       " 'occ2',\n",
       " 'occ3',\n",
       " 'occ4',\n",
       " 'occ5',\n",
       " 'occ6']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import io\n",
    "import pydot \n",
    "\n",
    "# Pick up all featurs columns from your data frame\n",
    "features = list(df.drop(['had_affair'],axis=1).columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8, now pick three models, with max_depth = 2, 3 and 4. You can pick the which ever criterions you want and visual the three trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint \n",
    "# model1 = DecisionTreeClassifier(max_depth=..., criterion= ...)\n",
    "# model1.fit(X_train, y_train)\n",
    "# model2 = DecisionTreeClassifier(max_depth=..., criterion= ...)\n",
    "# model2.fit(X_train, y_train)\n",
    "# model3 = DecisionTreeClassifier(max_depth=..., criterion= ...)\n",
    "# model3.fit(X_train, y_train)\n",
    "# Then display all 3 trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9. Now build a Random Forest Classifier with, say, 100 trees. Check the model performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
